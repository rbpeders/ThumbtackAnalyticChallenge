{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thumbtack Analytics Challenge\n",
    "  \n",
    "Thumbtack has decided to take a closer look at performance in two of its largest categories - House\n",
    "Cleaning and Local Moving. Please complete the analyses suggested below and overlay your own\n",
    "recommendations for how we can improve and grow our marketplace.\n",
    "\n",
    "    ● Based on the data, what types of pros are customers interested in?\n",
    "    \n",
    "        Customers have a high rate of Contact for pros with\n",
    "         1. Recent Site Activity (response time?)\n",
    "         2. More Reviews\n",
    "         3. High Search Rank\n",
    "        Somewhat suprisingly, rating was not a leading indicator of contacting or not\n",
    "         4. In the moving category, price was sensitive by about 20 bucks\n",
    "        \n",
    "        Differenciators for actually being hired\n",
    "         1. Recent Site Activity (response time?)\n",
    "         2. More Reveiews\n",
    "         \n",
    "\n",
    "    Dashboard below is a quick glance at the variables avaiable.\n",
    "\n",
    "https://public.tableau.com/views/ThumbtackSampleProj/ConsumerPreferences?:language=en&:embed_code_version=3&:loadOrderID=2&:display_count=y&publish=yes&:origin=viz_share_link\n",
    "\n",
    "    ● Based on the types of pros that customers are interested in, \n",
    "            how would you describe the quantity and quality of the search results? \n",
    "            What could be improved?\n",
    "\n",
    "     Quantity and Quality:    \n",
    "            * Very large presence of House Cleaner results that grade poorly in \n",
    "            features pertaining to being hired. (roughly 13x more than top graded) \n",
    "            * Local Moving is a job hired less and has a similar magnitude of 17x more \n",
    "            results in grade D than grade A\n",
    "            \n",
    "     What could be improved:\n",
    "            Regardless of the number of job actually accepted, if the population of pros\n",
    "            behaved in a way that reflected the top hires, the consumer would begin to \n",
    "            rely on other factors to pick whom to hire. (Perhaps availability, \n",
    "            response time, or positive reviews from friends/neighbors vs \"the crowd\". )\n",
    "            \n",
    "    Dashboard below is a quick glance at the grading spread for all the records of \n",
    "    search instances provided.\n",
    "\n",
    "\n",
    "https://public.tableau.com/views/ThumbtackSampleProjGrading/GradingDistrobution?:language=en&:retry=yes&:display_count=y&:origin=viz_share_link\n",
    "\n",
    "\n",
    "# Observations post ML building \n",
    "For trying to predict if a search result would be contacted or not, the features (columns) provided indicate a relatively strong ability to predict which search results receive contacts.  As for distinguishing which pros get hired once contacted, the results indicate the modeling ability at picking which pro gets hired is about as good as tossing a coin :/  \n",
    "\n",
    "Leading me to conclude, the features provided in the dataset are limited to making decent predictions on which pros search results gets contacted in both categories but not whom gets hired.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an outline of using machine learning in Python to express which\n",
    "\n",
    "\"features\" aka columns were the best predictors of being contacted and hired \n",
    "\n",
    "based on the sample data provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "\n",
    "Thumbtack is a marketplace for local services. Customers come to our website or mobile app to see our\n",
    "directory of service professionals (example) in nearly 500 categories. As part of the search experience, customers can provide some basic details about their projects in the search filters to see pros that best match their needs. Customers can also see pros’ price estimates for their projects. From the list of pros, customers can then explore pro profiles, contact the pros that interest them, and ultimately hire a pro. In this process, Thumbtack generates revenue by charging pros for each customer that contacts them.\n",
    "\n",
    "Downloaded Fiels : https://drive.google.com/drive/folders/1v8wmMVvQPFBHjtGutjYA4bL9V_eEt7Ii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitors CSV\n",
    "This dataset contains a list of search results. Each result is a pro that matched \n",
    "\n",
    "a specific visitor’s search.\n",
    "\n",
    "    ● row_number (integer): row number in data set\n",
    "    ● visitor_id (integer): unique identifier for the visitor that the \n",
    "        search result is associated with\n",
    "    ● search_timestamp (timestamp): timestamp of when the visitor loaded \n",
    "        the search results\n",
    "    ● category (string): category of the visitor’s search\n",
    "    ● pro_user_id (integer): unique identifier for the pro\n",
    "    ● num_reviews (integer): number of reviews that the pro had at the \n",
    "        time of the search\n",
    "    ● avg_rating (float): average rating across pro’s reviews\n",
    "    ● pro_last_active_time_before_search (timestamp): timestamp of when \n",
    "        the pro last responded to a customer that contacted them, prior \n",
    "        to the search_timestamp\n",
    "    ● cost_estimate_cents (integer): pro’s price estimate for the visitor’s \n",
    "        project, in cents. For House Cleaning searches, this is the price estimate \n",
    "        for the entire project. For Local Moving searches, this is the estimated \n",
    "        hourly rate.\n",
    "    ● result_position (integer): pro’s rank in search results. Rank = 1 means \n",
    "        the pro was ranked first among the search results.\n",
    "    ● service_page_viewed (boolean): TRUE indicates that the visitor clicked \n",
    "        to view the pro’s profile, FALSE otherwise\n",
    "\n",
    "\n",
    "# Contacts CSV\n",
    "This dataset contains a list of customers reaching out to pros. Each row is a \n",
    "\n",
    "visitor that reached out to a pro through a search in the Visitors CSV.\n",
    "    \n",
    "    ● visitor_id (integer): unique identifier for the visitor that reached\n",
    "        out to the pro\n",
    "    ● pro_user_id (integer): unique identifier for the pro that the visitor contacted\n",
    "    ● contact_id (integer): unique identifier for the visitor-pro contact\n",
    "    ● hired (boolean): TRUE indicates that the visitor eventually hired \n",
    "        the pro, FALSE otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "visitorsDf = pd.read_csv('ThumbTack Proj/Visitors.csv')\n",
    "visitorsDf = visitorsDf[['row_number', 'visitor_id', 'search_timestamp', 'category',\n",
    "       'pro_user_id', 'num_reviews', 'avg_rating','pro_last_active_time_before_search'\n",
    "        , 'cost_estimate_cents','result_position', 'service_page_viewed']]\n",
    "contactsDf = pd.read_csv('ThumbTack Proj/Contacts.csv')\n",
    "contactsDf = contactsDf[['visitor_id', 'pro_user_id', 'contact_id', 'hired']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26102"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitorsDf.columns\n",
    "len(visitorsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run profile report across each DF and decide which cols to keep/drop\n",
    "#ProfileReport(visitorsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['visitor_id', 'pro_user_id', 'contact_id', 'hired'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contactsDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run profile report across each DF and decide which cols to keep/drop\n",
    "#ProfileReport(contactsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Report Warnings\n",
    "This output was clipped from the report HTML renderings that I'm withholding from the final version of this notebook. Relevenct in making considerations for removal of sparce fields/features, constants, etc \n",
    "\n",
    "visitorsDf\n",
    "    \n",
    "    search_timestamp has a high cardinality: 3428 distinct values\t\n",
    "        High cardinality\n",
    "    pro_last_active_time_before_search has a high cardinality: 14610 distinct values\t\n",
    "        High cardinality\n",
    "    avg_rating has 1155 (4.4%) missing values\tMissing\n",
    "    pro_last_active_time_before_search has 1067 (4.1%) missing values\tMissing\n",
    "    cost_estimate_cents has 2158 (8.3%) missing values\tMissing\n",
    "    row_number has unique values\tUnique\n",
    "    num_reviews has 1155 (4.4%) zeros\tZeros\n",
    "\n",
    "contactsDf\n",
    "    \n",
    "    contact_id is highly correlated with visitor_id\tHigh correlation\n",
    "    visitor_id is highly correlated with contact_id\tHigh correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open Q's at this point - \n",
    "    \n",
    "    * Are visitor ID's unique to search results and regardless of if \n",
    "        visitor is a returning site visitor?\n",
    "            ** appears to be unique or obscured \n",
    "    * What happens when joining ProUser ID and Visitor ID?  Row count explode?\n",
    "            ** good to left join\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comboDf = pd.merge(visitorsDf, contactsDf, how='left', left_on=['visitor_id','pro_user_id'], right_on=['visitor_id','pro_user_id'])\n",
    "len(comboDf)\n",
    "#comboDf.head(40)\n",
    "#comboDf[comboDf['visitor_id']==343492100068655000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_number', 'visitor_id', 'search_timestamp', 'category',\n",
       "       'pro_user_id', 'num_reviews', 'avg_rating',\n",
       "       'pro_last_active_time_before_search', 'cost_estimate_cents',\n",
       "       'result_position', 'service_page_viewed', 'contact_id', 'hired'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comboDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comboDf['search_timestamp'] = pd.to_datetime(comboDf['search_timestamp'])\n",
    "comboDf['pro_last_active_time_before_search'] = pd.to_datetime(comboDf['pro_last_active_time_before_search'])\n",
    "comboDf['time_since_logged_in'] = ((comboDf['pro_last_active_time_before_search']\n",
    "                                -comboDf['search_timestamp'])/np.timedelta64(1,'h'))\n",
    "comboDf['contacted'] =~ comboDf['hired'].isna()\n",
    "comboDf['hired'] = comboDf['hired'].replace({True: 1, False: 0})\n",
    "comboDf['hour'] = comboDf['search_timestamp'].dt.hour\n",
    "#comboDf.groupby('contacted')['contacted'].count()\n",
    "#len(contactsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comboDf = comboDf[['row_number','category','hired','contacted',\n",
    "#       'num_reviews','avg_rating','cost_estimate_cents','result_position',\n",
    "#       'time_since_logged_in','hour']]\n",
    "\n",
    "movingDf = comboDf.where(comboDf['category'] == 'Local Moving (under 50 miles)').dropna(subset=['category'])\n",
    "    #len(movingDf) - 7048\n",
    "cleaningDf = comboDf.where(comboDf['category'] == 'House Cleaning').dropna(subset=['category'])\n",
    "    #len(cleaningDf) - 19054\n",
    "\n",
    "### Moving Category\n",
    "contacted_movingDf_X = movingDf[['num_reviews','avg_rating'\n",
    "                     ,'cost_estimate_cents','result_position','time_since_logged_in','hour']]\n",
    "contacted_movingDf_y = movingDf[['contacted']]\n",
    "\n",
    "movingDf = movingDf.where(comboDf['contacted'] == 1).dropna(subset=['contacted'])\n",
    "    #len(hired_movingDf_X) - 155\n",
    "hired_movingDf_X = movingDf[['num_reviews','avg_rating'\n",
    "                     ,'cost_estimate_cents','result_position','time_since_logged_in','hour']]\n",
    "hired_movingDf_y = movingDf[['hired']]\n",
    "\n",
    "### Cleaning Category \n",
    "contacted_cleaningDf_X = cleaningDf[['num_reviews','avg_rating'\n",
    "                     ,'cost_estimate_cents','result_position','time_since_logged_in','hour']]\n",
    "contacted_cleaningDf_y = cleaningDf[['contacted']]\n",
    "\n",
    "cleaningDf = cleaningDf.where(cleaningDf['contacted'] == 1).dropna(subset=['contacted'])\n",
    "    #len(hired_cleaningDf_X)  208\n",
    "hired_cleaningDf_X = cleaningDf[['num_reviews','avg_rating'\n",
    "                     ,'cost_estimate_cents','result_position','time_since_logged_in','hour']]\n",
    "hired_cleaningDf_y = cleaningDf[['hired']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "809"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sample sizes for the training sets to make sure none of the splits got to small\n",
    "len(hired_cleaningDf_y) \n",
    "#hired_movingDf_y.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning NAN values so training methods dont throw errors\n",
    "values = {'num_reviews':0 ,\n",
    "              'avg_rating': 0.00,\n",
    "              'cost_estimate_cents': 0,\n",
    "              'time_since_logged_in': 0\n",
    "             }\n",
    "contacted_movingDf_X = contacted_movingDf_X.fillna(value=values)\n",
    "hired_movingDf_X = hired_movingDf_X.fillna(value=values)\n",
    "contacted_cleaningDf_X = contacted_cleaningDf_X.fillna(value=values)\n",
    "hired_cleaningDf_X = hired_cleaningDf_X.fillna(value=values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "#Split data sets into splits for training where 25% of data is left out of \n",
    "    #training to use for validation tests\n",
    "X_train, X_test, y_train, y_test = train_test_split(hired_cleaningDf_X.to_numpy(),\n",
    "                                                hired_cleaningDf_y.to_numpy().ravel(),random_state = 0)\n",
    "clf = (GradientBoostingClassifier( random_state = 0\n",
    "#                                    ,learning_rate = .25,max_depth = 2,n_estimators = 8\n",
    "                                     )\n",
    "               .fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'learning_rate': [0.25, 0.1, 0.05, 0.01],\n",
    "           'max_depth' : np.linspace(1, 4, 4, endpoint=True),\n",
    "           'n_estimators': [1, 2, 4, 8]\n",
    "          }\n",
    "\n",
    "grid_clf_auc = GridSearchCV(clf, param_grid = grid_values, scoring = 'roc_auc')\n",
    "grid_clf_auc.fit(X_train, y_train)\n",
    "y_decision_fn_scores_auc = grid_clf_auc.decision_function(X_test) \n",
    "\n",
    "#print('Test set AUC: ', roc_auc_score(y_test, y_decision_fn_scores_auc))\n",
    "#print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "#print('Grid best score (AUC): ', grid_clf_auc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations post parameter search\n",
    "Good AUC scores for contact - pretty poor for hire\n",
    "\n",
    "Details on the AUC scores and interpreting their score for model performance\n",
    "https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5\n",
    "\n",
    "# contacted_movingDf_X\n",
    "    Test set AUC:  0.8103483661895761\n",
    "    Grid best parameter (max. AUC):  {'learning_rate': 0.25, 'max_depth': 2.0, 'n_estimators': 8}\n",
    "    Grid best score (AUC):  0.8027942934093323\n",
    "\n",
    "# hired_movingDf_X\n",
    "    Test set AUC:  0.46245107632093935\n",
    "    Grid best parameter (max. AUC):  {'learning_rate': 0.01, 'max_depth': 4.0, 'n_estimators': 2}\n",
    "    Grid best score (AUC):  0.4946914338501484\n",
    "\n",
    "# contacted_cleaningDf_X\n",
    "    Test set AUC:  0.8298953689757402\n",
    "    Grid best parameter (max. AUC):  {'learning_rate': 0.25, 'max_depth': 3.0, 'n_estimators': 8}\n",
    "    Grid best score (AUC):  0.8462944244914326\n",
    "\n",
    "# hired_movingDf_X\n",
    "    Test set AUC:  0.5615837539053112\n",
    "    Grid best parameter (max. AUC):  {'learning_rate': 0.05, 'max_depth': 1.0, 'n_estimators': 8}\n",
    "    Grid best score (AUC):  0.5639773130095711\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04224316 0.02392917 0.10179443 0.82228655 0.0097467  0.        ]\n",
      "Index(['num_reviews', 'avg_rating', 'cost_estimate_cents', 'result_position',\n",
      "       'time_since_logged_in', 'hour'],\n",
      "      dtype='object')\n",
      "Accuracy of GBDT classifier on training set: 0.90\n",
      "Accuracy of GBDT classifier on test set: 0.90\n",
      "ROC AUC of GBDT classifier on test set: 0.81\n"
     ]
    }
   ],
   "source": [
    "#Train contacted_moving classifier model at best parameter setting to obtain the \n",
    "#  weights of each feature passed \n",
    "\n",
    "contacted_moving_X_train, contacted_moving_X_test, contacted_moving_y_train, contacted_moving_y_test = train_test_split(contacted_movingDf_X.to_numpy(),\n",
    "                                                contacted_movingDf_y.to_numpy().ravel(),random_state = 0)\n",
    "\n",
    "contacted_moving_clf = (GradientBoostingClassifier( random_state = 0\n",
    "                                    , learning_rate = .25, max_depth = 2, n_estimators = 8\n",
    "                                     )\n",
    "               .fit(contacted_moving_X_train, contacted_moving_y_train))\n",
    "\n",
    "contacted_moving_clfscore = contacted_moving_clf.decision_function(contacted_moving_X_test)\n",
    "contacted_moving_fpr, contacted_moving_tpr, _ = roc_curve(contacted_moving_y_test, contacted_moving_clfscore)\n",
    "contacted_moving_roc_auc = auc(contacted_moving_fpr, contacted_moving_tpr)\n",
    "\n",
    "print(contacted_moving_clf.feature_importances_)\n",
    "print(contacted_movingDf_X.columns)\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(contacted_moving_clf.score(contacted_moving_X_train, contacted_moving_y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "    .format(contacted_moving_clf.score(contacted_moving_X_test, contacted_moving_y_test)))\n",
    "print('ROC AUC of GBDT classifier on test set: {:.2f}'\n",
    "    .format(contacted_moving_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34499328 0.         0.1612866  0.05919121 0.22233896 0.21218995]\n",
      "Index(['num_reviews', 'avg_rating', 'cost_estimate_cents', 'result_position',\n",
      "       'time_since_logged_in', 'hour'],\n",
      "      dtype='object')\n",
      "Accuracy of GBDT classifier on training set: 0.76\n",
      "Accuracy of GBDT classifier on test set: 0.84\n",
      "ROC AUC of GBDT classifier on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "#Train hired_moving classifier model at best parameter setting to obtain the \n",
    "#  weights of each feature passed \n",
    "\n",
    "hired_moving_X_train, hired_moving_X_test, hired_moving_y_train, hired_moving_y_test = train_test_split(hired_movingDf_X.to_numpy(),\n",
    "                                                hired_movingDf_y.to_numpy().ravel(),random_state = 0)\n",
    "\n",
    "hired_moving_clf = (GradientBoostingClassifier( random_state = 0\n",
    "                                    , learning_rate = .1, max_depth = 4, n_estimators = 2\n",
    "                                     )\n",
    "               .fit(hired_moving_X_train, hired_moving_y_train))\n",
    "\n",
    "hired_moving_clfscore = hired_moving_clf.decision_function(hired_moving_X_test)\n",
    "hired_moving_fpr, hired_moving_tpr, _ = roc_curve(hired_moving_y_test, hired_moving_clfscore)\n",
    "hired_moving_roc_auc = auc(hired_moving_fpr, hired_moving_tpr)\n",
    "\n",
    "print(hired_moving_clf.feature_importances_)\n",
    "print(hired_movingDf_X.columns)\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(hired_moving_clf.score(hired_moving_X_train, hired_moving_y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "    .format(hired_moving_clf.score(hired_moving_X_test, hired_moving_y_test)))\n",
    "print('ROC AUC of GBDT classifier on test set: {:.2f}'\n",
    "    .format(hired_moving_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04768329 0.07699484 0.04274963 0.77536943 0.0477916  0.0094112 ]\n",
      "Index(['num_reviews', 'avg_rating', 'cost_estimate_cents', 'result_position',\n",
      "       'time_since_logged_in', 'hour'],\n",
      "      dtype='object')\n",
      "Accuracy of GBDT classifier on training set: 0.96\n",
      "Accuracy of GBDT classifier on test set: 0.96\n",
      "ROC AUC of GBDT classifier on test set: 0.83\n"
     ]
    }
   ],
   "source": [
    "#Train contacted_cleaning classifier model at best parameter setting to obtain the \n",
    "#  weights of each feature passed \n",
    "\n",
    "contacted_cleaning_X_train, contacted_cleaning_X_test, contacted_cleaning_y_train, contacted_cleaning_y_test = train_test_split(contacted_cleaningDf_X.to_numpy(),\n",
    "                                                contacted_cleaningDf_y.to_numpy().ravel(),random_state = 0)\n",
    "\n",
    "contacted_cleaning_clf = (GradientBoostingClassifier( random_state = 0\n",
    "                                    , learning_rate = .25, max_depth = 3, n_estimators = 8\n",
    "                                     )\n",
    "               .fit(contacted_cleaning_X_train, contacted_cleaning_y_train))\n",
    "\n",
    "contacted_cleaning_clfscore = contacted_cleaning_clf.decision_function(contacted_cleaning_X_test)\n",
    "contacted_cleaning_fpr, contacted_cleaning_tpr, _ = roc_curve(contacted_cleaning_y_test, contacted_cleaning_clfscore)\n",
    "contacted_cleaning_roc_auc = auc(contacted_cleaning_fpr, contacted_cleaning_tpr)\n",
    "\n",
    "print(contacted_cleaning_clf.feature_importances_)\n",
    "print(contacted_cleaningDf_X.columns)\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(contacted_cleaning_clf.score(contacted_cleaning_X_train, contacted_cleaning_y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "    .format(contacted_cleaning_clf.score(contacted_cleaning_X_test, contacted_cleaning_y_test)))\n",
    "print('ROC AUC of GBDT classifier on test set: {:.2f}'\n",
    "    .format(contacted_cleaning_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0.]\n",
      "Index(['num_reviews', 'avg_rating', 'cost_estimate_cents', 'result_position',\n",
      "       'time_since_logged_in', 'hour'],\n",
      "      dtype='object')\n",
      "Accuracy of GBDT classifier on training set: 0.75\n",
      "Accuracy of GBDT classifier on test set: 0.72\n",
      "ROC AUC of GBDT classifier on test set: 0.56\n"
     ]
    }
   ],
   "source": [
    "#Train hired_moving classifier model at best parameter setting to obtain the \n",
    "#  weights of each feature passed \n",
    "\n",
    "hired_cleaning_X_train, hired_cleaning_X_test, hired_cleaning_y_train, hired_cleaning_y_test = train_test_split(hired_cleaningDf_X.to_numpy(),\n",
    "                                                hired_cleaningDf_y.to_numpy().ravel(),random_state = 0)\n",
    "\n",
    "hired_cleaning_clf = (GradientBoostingClassifier( random_state = 0\n",
    "                                    , learning_rate = .05, max_depth = 1, n_estimators = 8\n",
    "                                     )\n",
    "               .fit(hired_cleaning_X_train, hired_cleaning_y_train))\n",
    "\n",
    "hired_cleaning_clfscore = hired_cleaning_clf.decision_function(hired_cleaning_X_test)\n",
    "hired_cleaning_fpr, hired_cleaning_tpr, _ = roc_curve(hired_cleaning_y_test, hired_cleaning_clfscore)\n",
    "hired_cleaning_roc_auc = auc(hired_cleaning_fpr, hired_cleaning_tpr)\n",
    "\n",
    "print(hired_cleaning_clf.feature_importances_)\n",
    "print(hired_cleaningDf_X.columns)\n",
    "print('Accuracy of GBDT classifier on training set: {:.2f}'\n",
    "     .format(hired_cleaning_clf.score(hired_cleaning_X_train, hired_cleaning_y_train)))\n",
    "print('Accuracy of GBDT classifier on test set: {:.2f}'\n",
    "    .format(hired_cleaning_clf.score(hired_cleaning_X_test, hired_cleaning_y_test)))\n",
    "print('ROC AUC of GBDT classifier on test set: {:.2f}'\n",
    "    .format(hired_cleaning_roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
